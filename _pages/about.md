---
permalink: /
title: "Homepage"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---
# About Me
I am a passionate AI researcher specializing in privacy-preserving speech processing and audio data engineering, currently pursuing my Masterâ€™s degree at Shanghai Jiao Tong University (SJTU). My work bridges algorithmic innovation and practical implementation to address challenges in speech technology deployment, such as privacy risks in voice data and efficiency in large-scale audio curation.

# Education
M.Sc. in Electronic Information
Shanghai Jiao Tong University | 2023.09 â€“ 2026.03 (Expected)
â–¶ GPA: 3.46/4.0
â–¶ Key Courses: Reinforcement Learning Theory, Statistical Learning & Inference, Large-Scale Data Processing

B.Eng. in Information Management
Beihang University | 2018.09 â€“ 2022.06
â–¶ GPA: 3.42/4.0
â–¶ Key Courses: Artificial Intelligence & Deep Learning, Database Systems, Data Structures

# Research Experience
1. Speech Anonymization for Privacy Protection
Jiaxing South Lake Lab | 2024.08 â€“ Present

Developed a speaker embedding conversion framework using adversarial fake embeddings, reducing speaker identity leakage by 12% EER improvement.
Integrated ASR/NER with speech editing to sanitize sensitive content (e.g., names/locations), achieving 30% lower privacy exposure risk.
Designed evaluation protocols combining self-supervised learning (SSL) and speaker diversity metrics.
2. Large-Scale Audio Data Cleansing Pipeline
Lab Project | 2024.03 â€“ 2024.07

Optimized a three-stage pipeline (VAD â†’ DNSMOS â†’ speaker clustering), improving processing efficiency by 40%.
Discovered trade-offs: Denoising boosted speaker clustering accuracy by 15% but increased Whisper ASR WER by 8%.
Delivered a 6,000-hour Chinese TTS dataset, validated by MOS improvement (+0.8) on VALL-E synthesis models.
3. Target Speaker Extraction Model Optimization
WeSep Project | 2023.09 â€“ 2024.02

Trained and compared MossFormer/SepFormer/BSRNN models with complex-valued masking, achieving +2.1 dB SI-SNRi gains in noisy scenarios.
Explored fusion strategies for speaker embeddings, identifying concatenation as the optimal method.
Technical Expertise
Frameworks: PyTorch Â· Lhotse Â· WeSpeaker Â· PyAnnote
Speech Tasks: Voice Conversion (Seed-VC) Â· Speech Recognition (ZipFormer) Â· Music Source Separation (BSRNN)
Infrastructure: Linux Â· Slurm HPC

# Honors & Activities
3rd Prize, 33rd Beijing College Mathematics Competition (Non-Math Group) | 2023
Core Volunteer, 18th National Conference on Human-Computer Speech Communication | 2023
Collaboration
Open to research opportunities in:

Privacy-aware speech technology
Scalable audio data curation
Adaptive speech separation models
ðŸ“¬ Reach me at yunchongxiao@sjtu.edu.cn

Notes for Customization:
Add Publications/Preprints section once papers are accepted.
Include GitHub/Demo links for open-source projects.
Highlight lab affiliations (e.g., "Member of XXX Lab") if applicable.